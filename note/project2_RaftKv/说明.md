# project2 RaftKV

## 任务要求

1. 实现基本的`Raft`算法
2. 在`Raft`上建立一个可容错的KV服务器
3. 增加`raftlog GC`和`snapshot`的支持

## Part A

### a. 步骤

1. 领导选举
2. 日志复制
3. 原始的节点接口

### b. 代码结构

- 可以在`raft/raft.go`中的`raft.Raft`，看一些核心算法。也可以去看`raft/doc.go`

#### 1. Leader election

- 先从`raft.Raft.tick()`开始
- 如果要传数据，放进`raft.Raft.msgs`传
- 接受数据，通过`raft.Raft.Step()`
- 实现 test stub 函数，命名如`raft.Raft.bacomexxx`，用于raft节点状态发生变化的时候去更新内部状态
- `make project2aa`

#### 2. Log replication

- `raft/log.go`中的`raft.Raftlog`：用于管理`raft log`
- 还需要通过`raft/storage.go`中的`Storage`来获得`log entries`和`snapshot`这样的持久化数据
- `make project2ab`

#### 3. raw node interface

`raft/rawnode.go`的`raft.Rawnode`是上层接口，里面有

- `raft.Raft`
- `RawNode.Tick()`
- ###### `RawNode.Step()`
- `RawNode.Propose()`

`Ready`：另一个很重要的结构体。处理msg或者advancing逻辑时钟的时候，它会

- 发送信息给其他peers
- 把日志条目存到稳定的存储
- save hard state like the **term, commit index, and vote** to stable storage
- apply committed log entries to the state machine
- etc

### c. Hints

- 

### d. 代码

1. Config

   包含开启raft的参数

   | 成员          | 类型     | 备注                                                         | Test值 |
   | ------------- | -------- | ------------------------------------------------------------ | ------ |
   | ID            | uint64   | 不能为0                                                      | 1      |
   | peers         | []uint64 |                                                              | 1,2,3  |
   | ElectionTick  | int      | 参与选举的间隔，也就是说如果ElectionTick之内没有收到Leader的信息，自己就开始选举。一般ElectionTick=10*HeartbeatTick | 10     |
   | HeartbeatTick | int      |                                                              | 1      |
   | Storage       | Storage  |                                                              |        |
   | Applied       | uint64   |                                                              |        |

2. Raft

   | 成员                 | 类型                 | 备注                                       |
   | -------------------- | -------------------- | ------------------------------------------ |
   | id                   | uint64               |                                            |
   | Term                 | uint64               |                                            |
   | Vote                 | uint64               |                                            |
   | RaftLog              | *Raftlog             |                                            |
   | Prs                  | map[uint64]*Progress | 每个peer日志复制的过程Progress:next, match |
   | State                | StateType            |                                            |
   | votes                | map[uint64]bool      |                                            |
   | msgs                 | []pb.Message         |                                            |
   | Leads                | uint64               |                                            |
   | heartbeatTimeout     | int                  |                                            |
   | electionTimeout      | int                  |                                            |
   | **heartbeatElapsed** | int                  |                                            |
   | **electionElapsed**  | int                  |                                            |
   | leadTransferee       | uint64               |                                            |
   | PendingConfIndex     | uint64               |                                            |

3. Progress: 

   - next: 表示leader要发给follower的下一个日志条目的索引，
     - [x] **初始化**为`leader.lastIndex() + 1`
   - match: 表示已经复制给这个peer的最高索引值，
     - [x] **初始化为0**

4. Message

   | 成员                 | 类型        | 备注                                       |
   | -------------------- | ----------- | ------------------------------------------ |
   | MsgType              | MessageType | 信息的类型                                 |
   | To                   | *uint64*    |                                            |
   | From                 | *uint64*    |                                            |
   | Term                 | *uint64*    |                                            |
   | Logterm              | *uint64*    | append的日志的**前一个日志条目**的任期号   |
   | Index                | *uint64*    | append的日志的**前一个日志条目**的索引位置 |
   | Entries              | []*Entry    | 需要append的日志                           |
   | Commit               | *uint64*    | 当前领导人已经提交的最大的日志索引值       |
   | Snapshot             | *Snapshot   |                                            |
   | Reject               | *uint64*    | 是否拒绝                                   |
   | XXX_NoUnkeyedLiteral | struct{}    |                                            |
   | XXX_unrecognized     | []byte      |                                            |
   | XXX_sizecache        | *uint64*    |                                            |

5. MessageType

   | 成员名                 | 备注                                                  |
   | ---------------------- | ----------------------------------------------------- |
   | MsgHup                 | 开始选举，from 自己 to 自己                           |
   | MsgBeat                | 本地消息，告诉自己要发送下面的心跳了                  |
   | MsgPropose             | 建议将数据添加到Leader的日志条目中，并广播给followers |
   | MsgAppend              | followers收到添加日志req                              |
   | MsgAppendResponse      | leader收到添加日志resp                                |
   | MsgRequestVote         | follower收到投票req                                   |
   | MsgRequestVoteResponse | follower发送投票resp                                  |
   | MsgSnapshot            |                                                       |
   | MsgHeartbeat           | leader发送心跳req                                     |
   | MsgHeartbeatResponse   | follower发送心跳resp                                  |
   | MsgTransferLeader      |                                                       |
   | MsgTimeoutNow          |                                                       |

6. RaftLog

   | 成员              | 类型            | 备注                                              |
   | ----------------- | --------------- | ------------------------------------------------- |
   | storage           | Storage         | 包含快照以来的所有持久化数据                      |
   | committed         | *uint64         | [first:committed)，表示个数，初始化为**0**        |
   | applied           | *uint64*        | [first:applied)，表示个数，初始化为**0**          |
   | stabled           | *uint64*        | [first:stable), 表示个数，存storage里的持久化数据 |
   | entries           | []pb.Entry      | [first:last]                                      |
   | pendingSnapshot   | *pb.Snapshot    | **即将到来的不稳定的** Snapshot                   |
   | **函数**          | **返回类型**    | **备注**                                          |
   | Term(i *uint64*)  | (uint64, error) | 返回下标为 i 的Term                               |
   | LastIndex()       | uint64          | 返回 entries 的最后一个下标                       |
   | nextEnts()        | []pb.entry      | 返回 [applied, committed) 的日志                  |
   | unstableEntries() | []pb.entry      | 返回 [stabled, last] 的日志                       |

   ```go
   //  snapshot/first.....applied....committed....stabled.....last
   //  --------|------------------------------------------------|
   //                            log entries
   ```

   

7. network

   | 成员    | 类型                        | 备注                     |
   | ------- | --------------------------- | ------------------------ |
   | peer    | map[*uint64*]stateMachine   | Raft就是一个stateMachine |
   | storage | map[*uint64*]*MemoryStorage |                          |
   | dropm   | map[connem]*float64*        |                          |
   | ignorem | map[pb.MessageType]*bool*   | 需要忽略掉的MessageType  |
   | msgHook | func(pb.Message) *bool*     |                          |

8. Entry: 有两种类型：normal entries 和 configuration changes

   - normal entries:
   - configuration changes:  

   | 成员      | 类型      | 备注 |
   | --------- | --------- | ---- |
   | EntryType | EntryType |      |
   | Term      | *uint64*  |      |
   | Index     | *uint64*  |      |
   | Data      | []*byte*  |      |

9. Ready 可以把那些准备去读取的、存储到 stable storage 的、已 committed 或者 sent 给其他 peers 的 entries 和 messages 压缩。Ready中的所有字段都是只读的。

   | 成员             | 类型         | 备注                                                         |
   | ---------------- | ------------ | ------------------------------------------------------------ |
   | *SoftState       |              | 节点当前的不稳定状态。如果没有更新，软状态将为nil。不需要销魂或存储软状态。 |
   | pb.HardState     |              | 在发送消息之前**需要保存到 stable storage** 的节点的当前状态。如果没有更新， HardState 将等于 empty state 。 |
   | Entries          | []pb.Entry   | 特指那些在 Messages 发送前需要保存到 stable storage 的日志   |
   | Snapshot         | pb.Snapshot  | 特指需要存储到 stable storage 的快照                         |
   | CommittedEntries | []pn.Entry   | 特指要被 committed 到一个 store 的日志。他们要事先 committed 到 stable storage |
   | Messages         | []pb.Message | 特指在日志被 committed 到 stable storage 之后需要被 sent 的 messages。如果包含 MsgSnapshot ，应用必须在接受到快照或者 calling 快照失败的时候，向 raft 报告 |
   | **函数**         |              |                                                              |
   | Ready()          | Ready        | 返回这个节点在当前时间点的状态                               |
   | HasReady()       | bool         | 当使用者需要确认是否有 Ready 在等待时，调用                  |
   | Advance()        |              | 通告 RawNode 在上次的 Ready 结果中应用并保存了进度。         |
   | **SoftState**    |              |                                                              |
   | Lead             | uint64       |                                                              |
   | RaftState        | StateType    |                                                              |

   

### e. 论文

1. 三种状态
   - follower：被动接受leader和candidate的request并作出回应response
   - leader：处理所有客户端的requests
   - candidate：用于选举leader
2. 选举流程
   1. Follower递增自己的任期并设置为Candidate角色
   2. 投票给自己并且给其他节点发送投票请求
   3. 保持Candidate状态直到：
      - 同一个任期内获得大多数选票，成为Leader（一个节点在一个任期内只能给一个Candidate投票，任期相同则选票先到先得）并给其他节点发送心跳来保持自己的角色
      - 收到其他节点的RPC请求，如果请求中的任期大于等于Candidate当前的任期，认为其他节点成为了Leader，自身转换为Follower；如果其他节点的任期小于自身的任期，拒绝RPC请求并保持Candidate角色
      - 一段时间后仍旧没有Leader（可能是出现了平票的情况），则在选举超时后重新发起一轮选举（递增任期、发送投票请求）

### f. 错误

1. `raft_paper_test.go`的79, 148, 254, 260行：%s改成%v

2. `raft_test.go`的231, 359, 365, 427, 738, 741, 744, 754, 757, 771, 803, 806, 809, 828, 831, 834, 863, 1449, 1453, 1476, 1480行：%s改成%v

3. `testNonleaderElectionTimeoutRandomized`和`testNonleaderStartElection`矛盾！

   - `testNonleaderElectionTimeoutRandomized`：代码如下。`r.becomeCandidate()`，然后对`len(r.readMessages())==0`进行判断

     ```go
     // testNonleaderElectionTimeoutRandomized
     r.becomeCandidate()
     for len(r.readMessages()) == 0 {
         
     }
     ```
   
   - 但是在`testNonleaderStartElection`中看，进行`r.becomeCandidate()`之后，是会产生`r.msgs`的，也就是说`len(r.readMessages())!=0`。
   
     ```go
     // testNonleaderStartElection
     r.becomeCandidate()
     for i := 1; i < 2*et; i++ {
         r.tick()
     }
     msgs := r.readMessages()
     sort.Sort(messageSlice(msgs))
     wmsgs := []pb.Message{
         {From: 1, To: 2, Term: 2, MsgType: pb.MessageType_MsgRequestVote},
         {From: 1, To: 3, Term: 2, MsgType: pb.MessageType_MsgRequestVote},
     }
     if !reflect.DeepEqual(msgs, wmsgs) {
         t.Errorf("msgs = %v, want %v", msgs, wmsgs)
     }
     ```
     
     包括在论文中也有说到
     
     > On conversion to candidate, start election:
     > • Increment currentTerm
     > • Vote for self
     > • Reset election timer
     > • Send RequestVote RPCs to all other servers
     
     最后一条是要给其他servers发送RPCs，在本项目的代码中的表现也就是[把pb.MessageType_MsgRequestVote写入r.msgs中](https://github.com/tidb-incubator/tinykv/blob/course/doc/project2-RaftKV.md#leader-election)。~~所以我在`testNonleaderElectionTimeoutRandomized`的`r.becomeCandidate()`和`len(r.readMessages()) == 0`中间**添加了一行代码**`r.readMessages()`，用于去掉`r.becomeCandidate()`中的`r.msgs`~~
     
     ```go
     // testNonleaderElectionTimeoutRandomized
     r.becomeCandidate()
     r.readMessages()          // insert
     for len(r.readMessages()) == 0 {
         
     }
     ```
     
     发现后面还是有类似的测试代码，而且上论坛看其他同学也没有问类似的问题。所以改变了策略，把写`r.msgs`放到了`r.becomeCandidate`外面，看起来和实际的逻辑并不一致，但是也算是能把测试样例过了。

### g. 笔记

- `make`: make 也是用于内存分配的，但是和 new 不同，它只用于 chan、map 以及 slice 的内存创建，而且它返回的类型就是这三个类型本身，而不是他们的指针类型，因为这三种类型就是引用类型，所以就没有必要返回他们的指针了。

- 内嵌结构体：[go使用**匿名内嵌结构体**实现类似继承的功能](https://www.jianshu.com/p/ea9c3564d6b6)。例如：下面的结构体就可以继承`*network`的成员和函数

  ```go
  tests := []struct {
      *network
      state   StateType
      expTerm uint64
  }
  ```

- 

### h. 进度

| 时间      | 进度                                             |
| --------- | ------------------------------------------------ |
| 2021/1/12 | 完成了`raft_paper_test.go`中所有2AA的test        |
| 2021/1/13 | 2aa还剩4个test                                   |
| 2021/1/14 | 完成2aa，完成2ab一个test                         |
| 2021/1/15 | 搞清了各个数据结构以及msg的内部成员，完成3个test |
| 2021/1/21 | 完成2ab                                          |
| 2022/1/22 | 完成2a                                           |



## Part B

### a. 基本概念和步骤

1. 基本概念

- store 表示 tinykv-server 的实例
- Peer 表示在 Store 上正在运行的 Raft 节点
- Region 是一个 Peers 的集合，也叫 Raft group

![image-20210122153313111](C:\Users\81942\AppData\Roaming\Typora\typora-user-images\image-20210122153313111.png)

2. 两个主要步骤
   - raft workers 轮询通道 `raftCh` 去得到 `msgs` ， `msgs` 包含一个简单的驱动 `Raft module` 和 `Raft commands` 去发布日志的 `Tick`
   - 得到并处理从 `Raft module` 来的 `ready` ，其中包括发送 raft msgs ，对状态持久化，应用提交过的日志给 state machine 。一旦应用，就返回 response 给客户端

### b. 代码结构

- RaftStorage 在 raft_server.go 中
- `RaftStorage` 调用的 `Reader` or `Write` 会发送 `RaftCmdRequest`, 被定义在 `raft_cmdpb.proto`
- 接收者的 channel 是 `raftWorker` 的 `raftCh`
-  ( **核心** ) `RaftStore` 是 raftstore 的入口，在 `kv/raftstore/raftstore.go`
- 现在不用关注 `RaftStore` ，我们现在关注 `raftWorker` in `kv/raftstore/raft_worker.go`

### c. 需要做的

#### 1. peer storage

1. 三种 states
   - `RaftLocalState`: 存放当前 `Raft` 的 `HardState` 和 `LastLogIndex`
   - `RaftApplyState`: 存放 `Raft` 应用的 `LastLogIndex` 和一些截断了的日志信息
   - `RegionLocalState`: 存放 `Region` 信息和相应的 `Peer state`。
2. `PeerStorage.SaveReadyState`: 这个函数把 `raft.Ready` 中的数据保存到 `badger` 中
   - append log entries: 
     - 简单地把 `raft.Ready.Entries` 的所有日志保存到 `raftdb`，
     - 并删除所有之前 appended 的没有提交的日志；
     - 还要更新 `peer storage` 的 `RaftLocalState` 并存到 `raftdb`。
   - save the Raft hard state：指需要更新 `peer storage` 的 `RaftLocalState.HardState` 并存到 `raftdb`
3. **Hint**: 
   - 使用 **`WriteBatch`** 去存这些 `states`
   - 在`peer_storage.go` 中学习其他的函数，看如何 `read` 和 `write` 这些 `states`

#### 2. Raft ready process

1. 如何驱动 Part A 写的 Raft 模块，大多数代码都已经在下面两个文件中实现了。
   - `kv/raftstore/peer_msg_handler.go`
   - `kv/raftstore/peer.go`
2. 我只需要学习那些代码，并实现下面两个函数的逻辑就行了
   - `proposeRaftCommand`
   - `HandleRaftReady`

#### 3. 错误处理

1. 一些文件路径：
   - `proto/proto/errorpb.proto`
   - `kv/raftstore/util/error.go`
   - `kv/raftstore/cmd_resp.go` 中的 `BindErrResp` ：返回带有 error 的 resp 时，把那些 errors 转换成 `errorpb.proto`
2. 这里只需要考虑两个 errors
   - `ErrNotLeader`: the raft command is proposed on a follower. so use it to let the client try other peers.
   - `ErrStaleCommand`: 因为 leader 改变了，有些日志还没被提交和被新 leader 的日志覆盖掉。但是客户端并不知道，还傻傻的等着 resp。所以我需要返回这个 err 去让客户端知道这些事，并重新发送 command

1. Cluster

   | 成员名          | 类型                            | 备注                                       |
   | --------------- | ------------------------------- | ------------------------------------------ |
   | schedulerClient | *MockSchedulerClient            |                                            |
   | count           | int                             |                                            |
   | engines         | map[uint64]*engine_util.Engines | 各个 store 的 raftDB 和 kvDB               |
   | snapPaths       | map[uint64]string               | 各个 store 的 snapPath                     |
   | dirs            | []string                        |                                            |
   | simulator       | Simulator                       | Simulator 是一个接口，实际是 NodeSimulator |
   | cfg             | *config.Config                  |                                            |

2. Config

   | 成员名                              | 类型          | 备注 |
   | ----------------------------------- | ------------- | ---- |
   | StoreAddr                           | string        |      |
   | Raft                                | bool          |      |
   | SchedulerAddr                       | string        |      |
   | LogLevel                            | string        |      |
   | DBPath                              | string        |      |
   | RaftBaseTickInterval                | time.Duration |      |
   | RaftHeartbeatTicks                  | int           |      |
   | RaftElectionTimeoutTicks            | int           |      |
   | RaftLogGCTickInterval               | time.Duration |      |
   | RaftLogGcCountLimit                 | uint64        |      |
   | SplitRegionCheckTickInterval        | time.Duration |      |
   | SchedulerHeartbeatTickInterval      | time.Duration |      |
   | SchedulerStoreHeartbeatTickInterval | time.Duration |      |
   | RegionMaxSize                       | uint64        |      |
   | RegionSplitSize                     | uint64        |      |

3. metapb.Peer

   | 成员名  | 类型   | 备注 |
   | ------- | ------ | ---- |
   | Id      | uint64 |      |
   | StoreId | uint64 |      |

4. peer

   | 成员名                | 类型                    | 备注           |
   | --------------------- | ----------------------- | -------------- |
   | ticker                | *ticker                 |                |
   | RaftGroup             | *raft.RawNode           |                |
   | peerStorage           | *PeerStorage            |                |
   | Meta                  | *metapb.Peer            |                |
   | regionId              | uint64                  |                |
   | Tag                   | string                  |                |
   | proposals             | []*proposal             | 2b             |
   | LastCopactedIdx       | uint64                  | 2c             |
   | peerCache             | map[uint64]*metapb.Peer | 3b conf change |
   | PeersStartPendingTime | map[uint64]time.Time    | 3b conf change |
   | stopped               | bool                    | 3b conf change |
   | SizeDiffHint          | uint64                  | 3b split       |
   | ApproximateSize       | *uint64                 | 3b split       |

5. PeerStorage

   | 成员名               | 类型                 | 备注                          |
   | -------------------- | -------------------- | ----------------------------- |
   | region               | *metapb.Region       | peer 的当前 region 信息       |
   | raftState            | *rspb.RaftLocalState | peer 的当前 raft state        |
   | applyState           | *rspb.RaftApplyState | peer 的当前 apply state       |
   | snapState            | snap.SnapState       | 当前的 snapshot state         |
   | regionSched          | chan<- worker.Task   |                               |
   | snapTriedCnt         | int                  |                               |
   | Engines              | *engine_util.Engines | Raft and Kv                   |
   | Tag                  | string               |                               |
| **RaftApplyState**   |                      |                               |
   | AppliedIndex         | *uint64*             | 已应用的 Index ，初始化 0     |
   | TruncatedState       | *RaftTruncatedState  | 截断的最后一个日志 used in 2C |
   | TruncatedState.Index | uint64               | 初始化 0                      |
   | TruncatedState.Term  | uint64               | 初始化 0                      |
   | **RaftLocalState**   |                      |                               |
   | HardState            | *eraftpb.HardState   |                               |
   | LastIndex            | uint64               |                               |
   | LastTerm             | uint64               |                               |
   
   

### e. 笔记

- `strconv.Itoa`: 将数字转换成字符串
- 仅仅用作两个 `goroutine` 的同步时，可以用 `struct{}` 空结构体作为 `channels` 元素的类型
- 当一个channel作为一个函数参数时，它一般总是被专门用于**只发送或者只接收**。
- struct 中，小写开头的成员不可以由别的包访问，大写开头的成员可以由别的包访问
- 删除切片中的某个元素：`seq = append(seq[:index], seq[index+1:]...)`
- `panic: runtime error: invalid memory address or nil pointer dereference`: 对空指针进行了操作

### f. 问题

1. `eraftpb.Entry` 怎么写到 `badger.Entry` 中？

2. `raft_cmdpb.Request` 怎么传到 `Entry.Data` 里？

   纠结了一天。。。看了很多博客和代码，还去看了 Rust 的源码。后面突然想起来 pb 可以序列化。。。。

### g. 博客

Peer 封装了 Raft RawNode，我们对 Raft 的 Propose，ready 的处理都是在 Peer 里面完成的。

首先关注 propose 函数，Peer 的 propose 是外部 Client command 的入口。Peer 会判断这个 command 的类型：

- 如果是只读操作，并且 Leader 仍然是在 lease 有效期内，Leader 就能直接提供 local read，不需要走 Raft 流程。
- 如果是 Transfer Leader 操作，Peer 首先会判断自己还是不是 Leader，同时判断需要变成新 Leader 的 Follower 是不是有足够新的 Log，如果条件都满足，Peer 就会调用 RawNode 的 transfer_leader 命令。
- 如果是 Change Peer 操作，Peer 就会调用 RawNode propose_conf_change。
- 剩下的，Peer 会直接调用 RawNode 的 propose。

在 propose 之前，Peer 也会将这个 command 对应的 callback 存到 PendingCmd 里面，当对应的 log 被 applied 之后，会通过 command 里面唯一的 uuid 找到对应的 callback 调用，并给 Client 返回相应的结果。

另一个需要关注的就是 Peer 的 handle_raft_ready 系列函数，在之前 Raft 章节里面介绍过，当一个 RawNode ready 之后，我们需要对 ready 里面的数据做一系列处理，包括将 entries 写入 Storage，发送 messages，apply committed_entries 以及 advance 等。这些全都在 Peer 的 handle_raft_ready 系列函数里面完成。

对于 committed_entries 的处理，Peer 会解析实际的 command，调用对应的处理流程，执行对应的函数，譬如 exec_admin_cmd 就执行 ConfChange，Split 等 admin 命令，而 exec_write_cmd 则执行通常的对 State Machine 的数据操作命令。为了保证数据的一致性，Peer 在 execute 的时候，都只会将修改的数据保存到 RocksDB 的 WriteBatch 里面，然后在最后原子的写入到 RocksDB，写入成功之后，才修改对应的内存元信息。如果写入失败，我们会直接 panic，保证数据的完整性。

在 Peer 处理 ready 的时候，我们还会传入一个 Transport 对象，用来让 Peer 发送 message，Transport 的 trait 定义如下：

```fallback
pub trait Transport: Send + Clone {
    fn send(&self, msg: RaftMessage) -> Result<()>;
}
```

它就只有一个函数 send，TiKV 实现的 Transport 会将需要 send 的 message 发到 Server 层，由 Server 层发给其他的节点。

## Part C

快照的定义：当前 storage 中的**所有**存储状态。

### a. 代码结构

#### 1. Raft

- 看 `eraftpb.Snapshot` 的 pb 文件，里面的 `data` 并不代表真实的状态机数据，而是一些被上层函数使用的元数据，现在可以忽略。
- 要 send Snapshot 信息的时候，可以用 `Storage.Snapshot()` 去得到。
- 状态机数据的建立和发送是在 `raftstore` 中实现的。
- 可以假设一旦 `Storage.Snapshot()` 运行成功，对于 leader 来说把信息传给 follower 是安全的
- follower 调用 `handleSnapshot` ，仅仅是重新存储一些 raft 的内部状态，例如：term, commit index, membership information 等。这些状态在 message 的 `eraftpb.SnapshotMetadata` 中。

#### 2. raftstore

- `raftlog-gc worker`: 
- `region worker`
- 需不需要 gc log 取决于 `onRaftGcLogTick()` 中的`RaftLogGcCountLimit`
- 需要 gc log 的话，会发送 admin command `CompactLogRequest` 
- `CompactLogRequest` 会修改 metadata ，即 ***peer_storage* 中的 `RaftApplyState` 中的 `RaftTruncatedState`** 。
- 修改后，需要通过 ***peer_msg_handler* 中的 `ScheduleCompactLog`** 给 raftlog-gc worker 启动一个任务
- raftlog-gc worker 会异步**删除掉 log**。（仅仅是删掉而已，从 db 中删掉）
  - （自己添加）
  - 异步删除 db 中的 log 之后，可以从 Advance 的 maybeCompact() 知道，db 中的 log 已经删除了，所以把 RaftLog 里的 Entries 删掉，并且更新
  - 在 leader 的 RaftLog 更新之后，它的 first Index 就会变化，所以在 propose 请求的时候，如果 first Index > prs[peer].match 的话，则开始发送快照
    - 但是快照并不能马上生成成功，需要时间，所以这里是异步进行的，所以在第一次 propose 的时候， leader 并不能发送真正的 snapshot 过去，而是只能发送一个 pendingSnapshot 过去，告诉 follower ， snapshot 在生成了，别催了别催了。
    - 所以第一次 propose 的时候， follower 简单更新一下状态，
    - 到了第二次 propose 的时候，等待 snapshot 生成完毕，才真正的发送 snapshot 给 follower
    - follower 接收到实实在在的 snapshot 后，对 napshot 进行 apply。
- 由于日志压缩了，raft 需要发送快照给其他 peer ，raft 会调用 Storage.Snapshot()，在调用 peer_storage.Snapshot() 的时候，它会发送一个 RegionTaskGen 的任务给 region worker 。具体的处理和实现在 kv/raftstore/runner/region_task.go 。它 scan 底层的存储器生成一个快照，并通过管道发送出去，下一次调用 Snapshot()  的时候，它会检查快照是否生成完毕。如果结束了， raft 会发送快照给其他 peers 。快照的发送和接受工作是由 kv/storage/raft_storage/snap_runner.go 处理的。你不需要查看其中的细节，只需要知道 snapshot 信息在被接受之后是由 **onRaftMsg** 处理的
- 快照会在下次的 raft ready 中反射出来，所以你需要做的事是去修改 raft ready 的过程以去处理 snapshot 的情况。当你确定你应用了快照时，你可以像 RaftLocalState, RaftApplyState, and RegionLocalState 一样更新 peer storage's memory state。当然，也不要忘记去把这些状态持久化到 kvdb 和 raftdb 中，不要忘了移除 kvdb 和 raftdb 中的不需要的数据。此外，你还需要...

